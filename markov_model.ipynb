{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2a959f7-fdf1-4154-b92d-e053cdfd273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "import inflect\n",
    "import queue\n",
    "import random\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4646c71a-0530-440a-b1db-56f9d65841f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_contents_section(line):\n",
    "    \"\"\"Check if the line is a 'contents' section.\"\"\"\n",
    "    return line == 'contents' or line == 'table of contents'\n",
    "\n",
    "def is_chapter_or_numbered(line):\n",
    "    \"\"\"Check if the line starts with a number, Roman numeral, or the word 'chapter'.\"\"\"\n",
    "    return bool(re.match(r'^(\\d+|i{1,3}|iv|v{1,3}|ix|x|chapter)\\b', line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23da3e8a-904b-4042-a95a-60f61779f1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite(file_path, output_path): #remove header\n",
    "    try:\n",
    "        skip_section = False\n",
    "\n",
    "        with open(file_path, 'r', encoding='utf-8') as infile, open(output_path, 'w', encoding='utf-8') as outfile:\n",
    "            for line in infile:\n",
    "                processed_line = line.strip().lower() # Strip leading/trailing whitespace, lowercase the line\n",
    "                if processed_line:\n",
    "                    if is_contents_section(processed_line):\n",
    "                        skip_section = True\n",
    "                        continue\n",
    "        \n",
    "                    if skip_section:\n",
    "                        if is_chapter_or_numbered(processed_line):\n",
    "                            continue\n",
    "                        else:\n",
    "                            skip_section = False\n",
    "                    outfile.write(processed_line + '\\n')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8a7dc99-1745-4a17-9ac8-c0a595425763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    processed = text.strip().lower()\n",
    "    \n",
    "    re_html = re.compile('<.*?>')\n",
    "    processed = re_html.sub(r'', processed) #remove html\n",
    "\n",
    "    re_url = re.compile(r'https?://[^\\s/$.?#].[^\\s]*|www\\.[^\\s/$.?#].[^\\s]*')\n",
    "    processed = re_url.sub('', processed)\n",
    "\n",
    "    punctuations = set(string.punctuation) #remove selective punctuations\n",
    "    punctuations = (punctuations - {'.','!','?'})\n",
    "    punctuations = ''.join(punctuations)\n",
    "\n",
    "    pun_dict = {\".\": \" . \", \"!\" : \" ! \", \"?\":\" ? \"} # to treat punctuations as a seprate word\n",
    "    processed = processed.translate(str.maketrans(pun_dict))\n",
    "\n",
    "    p = inflect.engine()\n",
    "    words = processed.split()\n",
    "    processed = \" \".join([p.number_to_words(w) if w.isnumeric() else w for w in words]) #numbers to words\n",
    "    \n",
    "    processed = processed.translate(str.maketrans(\"\",\"\",punctuations))\n",
    "\n",
    "    return processed.split()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc7a5145-cd3a-4522-a635-d039aa1e0770",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"My name is Ankush. Whats yours? this is a (test case), adding 5412 number check, My name is Dhara. Dhara is my name,\"\n",
    "text = preprocessing(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9391b50-975f-4f18-8fb6-01c0af836c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_tf(text, tf):\n",
    "    q = deque(text) \n",
    "    if len(q) < 2:  # Ensure there are enough elements to process\n",
    "        return tf\n",
    "\n",
    "    previous = q.popleft()\n",
    "    current = q.popleft()\n",
    "\n",
    "    while q:\n",
    "        next_word = q.popleft()\n",
    "\n",
    "        if previous in tf:\n",
    "            if current in tf[previous]:\n",
    "                if next_word in tf[previous][current]:\n",
    "                    tf[previous][current][next_word] += 1\n",
    "                else:\n",
    "                    tf[previous][current][next_word] = 1\n",
    "            else:\n",
    "                tf[previous][current] = {next_word: 1}\n",
    "        else:\n",
    "            tf[previous] = {current: {next_word: 1}}\n",
    "\n",
    "        previous = current\n",
    "        current = next_word\n",
    "\n",
    "    return tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18256f14-20e6-494e-9484-36f80432e6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'my': {'name': {'is': 2}}, 'name': {'is': {'ankush': 1, 'dhara': 1}}, 'is': {'ankush': {'.': 1}, 'a': {'test': 1}, 'dhara': {'.': 1}, 'my': {'name': 1}}, 'ankush': {'.': {'whats': 1}}, '.': {'whats': {'yours': 1}, 'dhara': {'is': 1}}, 'whats': {'yours': {'?': 1}}, 'yours': {'?': {'this': 1}}, '?': {'this': {'is': 1}}, 'this': {'is': {'a': 1}}, 'a': {'test': {'case': 1}}, 'test': {'case': {'adding': 1}}, 'case': {'adding': {'five': 1}}, 'adding': {'five': {'thousand': 1}}, 'five': {'thousand': {'four': 1}}, 'thousand': {'four': {'hundred': 1}}, 'four': {'hundred': {'and': 1}}, 'hundred': {'and': {'twelve': 1}}, 'and': {'twelve': {'number': 1}}, 'twelve': {'number': {'check': 1}}, 'number': {'check': {'my': 1}}, 'check': {'my': {'name': 1}}, 'dhara': {'.': {'dhara': 1}, 'is': {'my': 1}}}\n"
     ]
    }
   ],
   "source": [
    "tf = {}\n",
    "tf = update_tf(text,tf)\n",
    "print(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e005236-ab0f-4003-98a9-4fea40f86fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engine(tf,file_path,lines_per_chunk=100):\n",
    "    output_path = \"data\\\\out\"\n",
    "    rewrite(file_path,output_path)\n",
    "    try:\n",
    "        with open(output_path, 'r', encoding='utf-8') as infile:\n",
    "            while True:\n",
    "                lines = [infile.readline() for _ in range(lines_per_chunk)]\n",
    "                lines = [line for line in lines if line]\n",
    "                if not lines:  # End of file\n",
    "                    break\n",
    "                lines = \" \".join(lines)\n",
    "                processed = preprocessing(lines)\n",
    "                tf = update_tf(processed,tf)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")  \n",
    "    return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "121a0d08-6d2a-4933-88b8-d8a16f367755",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = {}\n",
    "tf = engine(tf,'data\\\\Alic.txt')\n",
    "tf = engine(tf,'data\\\\gatsby.txt')\n",
    "tf = engine(tf,'data\\\\prid.txt')\n",
    "tf = engine(tf,'data\\\\The_Project_Gutenberg_eBook_of_Moby.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba7c61cd-6b06-4d0f-84fd-de47ca9e3463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: 'utf-8' codec can't decode byte 0xff in position 3697: invalid start byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xff in position 7478: invalid start byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xff in position 5470: invalid start byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xff in position 1142: invalid start byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xff in position 5909: invalid start byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xda in position 537: invalid continuation byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xfe in position 905: invalid start byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xe9 in position 886: invalid continuation byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xe9 in position 1028: invalid continuation byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xaa in position 680: invalid start byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xfe in position 374: invalid start byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xfe in position 400: invalid start byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xd4 in position 1163: invalid continuation byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xd5 in position 523: invalid continuation byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xd5 in position 699: invalid continuation byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xe4 in position 38: invalid continuation byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xe4 in position 38: invalid continuation byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xe4 in position 38: invalid continuation byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xb2 in position 7994: invalid start byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xb5 in position 894: invalid start byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xe4 in position 39: invalid continuation byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xe4 in position 39: invalid continuation byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xe4 in position 38: invalid continuation byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xe4 in position 2133: invalid continuation byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0x94 in position 38: invalid start byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xaa in position 582: invalid start byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xfe in position 2654: invalid start byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xfe in position 436: invalid start byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xfe in position 1146: invalid start byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xd1 in position 1293: invalid continuation byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xd1 in position 531: invalid continuation byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xd1 in position 1140: invalid continuation byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xd1 in position 1266: invalid continuation byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xd1 in position 499: invalid continuation byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xba in position 2957: invalid start byte\n",
      "An error occurred: \n",
      "An error occurred: 'utf-8' codec can't decode byte 0xa0 in position 1020: invalid start byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xfd in position 410: invalid start byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xfd in position 541: invalid start byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xfd in position 447: invalid start byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xff in position 880: invalid start byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xed in position 694: invalid continuation byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xba in position 710: invalid start byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xb6 in position 777: invalid start byte\n",
      "An error occurred: 'utf-8' codec can't decode byte 0xb9 in position 879: invalid start byte\n"
     ]
    }
   ],
   "source": [
    "for dirpath, dirnames, filenames in os.walk(\"D:\\\\Rutgers\\\\Sem7\\\\ML\\\\NorthEastern\\\\hw1\\\\20news-bydate\\\\20news-bydate-train\"):\n",
    "        for filename in filenames:\n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "            engine(tf, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50a557b7-392b-415c-a81e-7b60f0931400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_numbers(nested_dict, frequency=None):\n",
    "    if frequency is None:\n",
    "        frequency = {}\n",
    "\n",
    "    for key, value in nested_dict.items():\n",
    "        # Check if the key is a number and update frequency\n",
    "        if isinstance(key, int):\n",
    "            frequency[key] = frequency.get(key, 0) + 1\n",
    "\n",
    "        # Check if the value is a dictionary and recurse\n",
    "        if isinstance(value, dict):\n",
    "            count_numbers(value, frequency)\n",
    "        elif isinstance(value, int):\n",
    "            # If value is a number, update frequency\n",
    "            frequency[value] = frequency.get(value, 0) + 1\n",
    "\n",
    "    return frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2e9f462-7f09-4c3d-bf9f-c431178b023f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{80: 3, 52: 9, 24: 16, 59: 2, 1: 327946, 10: 203, 4: 4485, 8: 614, 2: 20358, 6: 807, 16: 66, 26: 22, 3: 5624, 7: 589, 5: 1437, 54: 2, 17: 53, 11: 157, 12: 160, 15: 77, 23: 21, 13: 129, 21: 33, 9: 311, 25: 13, 71: 2, 18: 49, 19: 45, 20: 44, 41: 6, 50: 5, 35: 15, 22: 26, 49: 2, 40: 7, 14: 92, 29: 13, 30: 12, 51: 2, 28: 15, 86: 1, 72: 2, 32: 9, 42: 4, 27: 14, 57: 3, 78: 1, 43: 5, 56: 4, 70: 2, 37: 3, 31: 8, 36: 7, 48: 4, 47: 2, 65: 2, 45: 3, 64: 2, 166: 1, 68: 3, 44: 3, 63: 2, 55: 4, 34: 2, 212: 1, 122: 1, 39: 3, 81: 1, 87: 1, 92: 1, 123: 1, 79: 1, 69: 2, 38: 4, 33: 7, 60: 2, 73: 1, 91: 1, 61: 1, 102: 1, 76: 2, 99: 1, 126: 1, 88: 2, 98: 1, 46: 1, 135: 1, 232: 1, 143: 1}\n"
     ]
    }
   ],
   "source": [
    "result = count_numbers(tf)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf5d35e7-9068-4a04-844a-0f32315d704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(markov_model, start_word1, start_word2, max_words=500):\n",
    "    if start_word1 not in markov_model or start_word2 not in markov_model.get(start_word1, {}):\n",
    "        return \"Starting words not found in the model.\"\n",
    "\n",
    "    sentence = [start_word1, start_word2]\n",
    "\n",
    "    while len(sentence) < max_words:\n",
    "        word1, word2 = sentence[-2], sentence[-1]\n",
    "\n",
    "        next_words = markov_model.get(word1, {}).get(word2, None)\n",
    "        if not next_words:\n",
    "            break\n",
    "\n",
    "        next_word = random.choices(\n",
    "            population=list(next_words.keys()),\n",
    "            weights=list(next_words.values()),\n",
    "            k=1\n",
    "        )[0]\n",
    "\n",
    "        sentence.append(next_word)\n",
    "\n",
    "    return ' '.join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7adf412c-c25d-4671-936b-0e651497db55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appalled me . but these marks do not know how mr . bennet for anything about it if he cuts off one of its narrowest parts . sir william and mr . gatsby his hands on her mind was visible in some small degree of importance which is thirty thousand pounds were in a bit if you only kept on good authority that sperm is of a sudden terrific downward jerking of the ponies is delightful . we were somebody she knew was deserved . the band below and were it not equal to it . hark ! chapter thirtythree . this observation would not catch . but still retained but his next return into hertfordshire with the crew striking up a peculiar form some two feet above the gunwale again and mr . darcy was delighted with their hands while his three whales in a few brisk phrases . “i’ll telephone for george ? maybe even if encountered should be used on or associated in any doubt of his character never occurred to me sir” said the caterpillar . “is she from new york through numerous populous cities and most thriving villages through which he was so vexed to see her again was she was and waited . the honor and the queen said severely “who is he ? ” elizabeth had scarcely needed an invitation to remain at netherfield in the united states . compliance requirements are not going to bed at sea . he and his behaviour to myself i might have been captured far north be it known that wickham has deserved to lose him now—don’t oh don’t ! ” “caramba ! have ye seen him lay unrolled one of her uncle and aunt . their house was in no instance done away . ” “no she would never romp again like the dyspeptic old woman of distinguished birth . she would altogether be a judge . in strange hieroglyphics in the family . mrs . bennet who had been just as if she did conquer her father’s incredulity and mortification attendant on such a companion . but i’d like to have left netherfield for the good conduct the probity trust . i do not think that you can see . ” “we’re always the first watch and seals “you may as well as some women can never see a blemish and who she was convinced would receive any satisfaction she had been barbarously used by them again in quest of the sperm whales are harpooned for one i tell you ! ’ i said that henceforth we were most unhappily deceived and by nameless blandishments as of ropes and hawsers coiled away in those for ever to pay him a disgust which turned the key and if i have ever known before . and so dead to anything like oil . no great distance below the surface of his officers and though i have frequently wished to avoid it as the ship’s getting out of\n"
     ]
    }
   ],
   "source": [
    "start_word1 = random.choice(list(tf.keys()))\n",
    "start_word2 = random.choice(list(tf[start_word1].keys()))\n",
    "print(generate_sentence(tf,start_word1,start_word2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd431986-6ef6-4f99-a77f-55f63df12047",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
